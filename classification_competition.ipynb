{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification_competition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuoOFjmCG46i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f5dcdf-6c6c-45a0-bae0-b3c590ca18f9"
      },
      "source": [
        "!pip install -q -U tensorflow-text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.6MB 7.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHLBKa-XH2Cy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef143fc-90b2-436b-c95c-f0e97458805e"
      },
      "source": [
        "!pip install -q -U tf-models-official"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 849kB 5.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 36.7MB 1.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 38.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 34.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 11.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 38.5MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_TJW0IjIAEm"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text  # A dependency of the preprocessing model\n",
        "from official.nlp import optimization\n",
        "import numpy as np\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSOcFHlpGYxa",
        "outputId": "2a374e64-717f-4de1-ad41-29d72c0b60f1"
      },
      "source": [
        "if os.environ['COLAB_TPU_ADDR']:\n",
        "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "  tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "  print('Using TPU')\n",
        "elif tf.test.is_gpu_available():\n",
        "  strategy = tf.distribute.MirroredStrategy()\n",
        "  print('Using GPU')\n",
        "else:\n",
        "  raise ValueError('Running on CPU is not recomended.')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mf-rJZ9IP76"
      },
      "source": [
        "# Select BERT model\n",
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/1'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4SP3ZHUJSv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71cb915d-9ffa-4dee-805a-3af344bdf7ad"
      },
      "source": [
        "# Download dataset\n",
        "url = 'https://raw.githubusercontent.com/CS410Fall2020/ClassificationCompetition/main/data/train.jsonl'\n",
        "dataset_path = tf.keras.utils.get_file('train.jsonl', url)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/CS410Fall2020/ClassificationCompetition/main/data/train.jsonl\n",
            "3874816/3871480 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGtomUvtOncR"
      },
      "source": [
        "# Preprocess data into tf.data.Dataset\n",
        "def preprocess_dataset(dataset_path, split):\n",
        "  \"\"\"Processes Twitter sarcasm data into tf.data.Dataset.\n",
        "    \n",
        "  Args:\n",
        "    dataset_path: str path of jsonl dataset.\n",
        "    split: str designating train or test dataset, either 'train' or 'test'.\n",
        "    \n",
        "  Returns:\n",
        "    A tf.data.Dataset of the Twitter sarcasm data, retaining only the response\n",
        "    tweet, the last context tweet, and the label if present.\n",
        "  \"\"\"\n",
        "  \n",
        "  with open(dataset_path, 'r') as file:\n",
        "    dict_list = [json.loads(line) for line in file.readlines()]\n",
        "\n",
        "  if split == 'train':\n",
        "    features = {'response': [], 'context': [], 'label': []}\n",
        "    for d in dict_list:\n",
        "      features['response'].append(d['response'])\n",
        "      features['context'].append(d['context'][-1])  # Only use last context element for simplicity\n",
        "      if d['label'] == 'SARCASM':\n",
        "        features['label'].append(1)\n",
        "      else:\n",
        "        features['label'].append(0)\n",
        "  else:\n",
        "    features = {'response': [], 'context': []}\n",
        "    for d in dict_list:\n",
        "      features['response'].append(d['response'])\n",
        "      features['context'].append(d['context'][-1])  # Only use last context element for simplicity\n",
        "\n",
        "  return tf.data.Dataset.from_tensor_slices(features)\n",
        "\n",
        "dataset = preprocess_dataset(dataset_path, 'train')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AF5CohslG2-"
      },
      "source": [
        "# Shuffle dataset and split into train and validation sets\n",
        "train_ratio = 0.8\n",
        "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
        "\n",
        "dataset = dataset.shuffle(dataset_size)\n",
        "in_memory_train_ds = dataset.take(int(train_ratio * dataset_size))\n",
        "train_size = tf.data.experimental.cardinality(in_memory_train_ds).numpy()\n",
        "in_memory_val_ds = dataset.skip(int(train_ratio * dataset_size))\n",
        "val_size = tf.data.experimental.cardinality(in_memory_val_ds).numpy()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWgW9shcoK-c"
      },
      "source": [
        "# BERT preprocessing\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=128):\n",
        "  \"\"\"Returns Model mapping string features to BERT inputs.\n",
        "\n",
        "  Args:\n",
        "    sentence_features: a list with the names of string-valued features.\n",
        "    seq_length: an integer that defines the sequence length of BERT inputs.\n",
        "\n",
        "  Returns:\n",
        "    A Keras Model that can be called on a list or dict of string Tensors\n",
        "    (with the order or names, resp., given by sentence_features) and\n",
        "    returns a dict of tensors for input to BERT.\n",
        "  \"\"\"\n",
        "\n",
        "  input_segments = [\n",
        "      tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
        "      for ft in sentence_features]\n",
        "\n",
        "  # Tokenize the text to word pieces.\n",
        "  bert_preprocess = hub.load(tfhub_handle_preprocess)\n",
        "  tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "  segments = [tokenizer(s) for s in input_segments]\n",
        "\n",
        "  # Optional: Trim segments in a smart way to fit seq_length.\n",
        "  # Simple cases (like this example) can skip this step and let\n",
        "  # the next step apply a default truncation to approximately equal lengths.\n",
        "  truncated_segments = segments\n",
        "\n",
        "  # Pack inputs. The details (start/end token ids, dict of output tensors)\n",
        "  # are model-dependent, so this gets loaded from the SavedModel.\n",
        "  packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                          arguments=dict(seq_length=seq_length),\n",
        "                          name='packer')\n",
        "  model_inputs = packer(truncated_segments)\n",
        "  return tf.keras.Model(input_segments, model_inputs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-4H7a3nHcVp"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def load_dataset(in_memory_ds, split, batch_size, bert_preprocess_model):\n",
        "  ds = in_memory_ds\n",
        "  if split == 'train':\n",
        "    ds = ds.shuffle(train_size)\n",
        "    ds = ds.repeat()\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.map(lambda x: (bert_preprocess_model(x), x['label']))\n",
        "  ds = ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGWtviLspVqB"
      },
      "source": [
        "# Define model\n",
        "def build_classifier_model(num_classes):\n",
        "  inputs = dict(\n",
        "      input_word_ids=tf.keras.layers.Input(shape=(None,), dtype=tf.int32),\n",
        "      input_mask=tf.keras.layers.Input(shape=(None,), dtype=tf.int32),\n",
        "      input_type_ids=tf.keras.layers.Input(shape=(None,), dtype=tf.int32),\n",
        "  )\n",
        "\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='encoder')\n",
        "  net = encoder(inputs)['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(rate=0.1)(net)\n",
        "  net = tf.keras.layers.Dense(num_classes, activation=None, name='classifier')(net)\n",
        "  return tf.keras.Model(inputs, net, name='prediction')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uUWJGntIW9L",
        "outputId": "5c324bb6-7e9e-4391-ac9f-636d4dd54ec5"
      },
      "source": [
        "# Train model\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "init_lr = 2e-5\n",
        "\n",
        "print(f'Fine tuning {tfhub_handle_encoder} model')\n",
        "bert_preprocess_model = make_bert_preprocess_model(['context', 'response'])\n",
        "\n",
        "with strategy.scope():\n",
        "\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  metrics = tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)\n",
        "\n",
        "  train_dataset = load_dataset(in_memory_train_ds, 'train', batch_size, bert_preprocess_model)\n",
        "  steps_per_epoch = train_size // batch_size\n",
        "  num_train_steps = steps_per_epoch * epochs\n",
        "  num_warmup_steps = num_train_steps // 10\n",
        "\n",
        "  val_dataset = load_dataset(in_memory_val_ds, 'val', batch_size, bert_preprocess_model)\n",
        "  val_steps = val_size // batch_size\n",
        "\n",
        "  classifier_model = build_classifier_model(num_classes=2)\n",
        "\n",
        "  optimizer = optimization.create_optimizer(\n",
        "      init_lr=init_lr,\n",
        "      num_train_steps=num_train_steps,\n",
        "      num_warmup_steps=num_warmup_steps,\n",
        "      optimizer_type='adamw')\n",
        "\n",
        "  classifier_model.compile(optimizer=optimizer, loss=loss, metrics=[metrics])\n",
        "\n",
        "  classifier_model.fit(\n",
        "      x=train_dataset,\n",
        "      validation_data=val_dataset,\n",
        "      steps_per_epoch=steps_per_epoch,\n",
        "      epochs=epochs,\n",
        "      validation_steps=val_steps)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine tuning https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3 model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:543: UserWarning: Input dict contained keys ['label'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 49s 395ms/step - loss: 0.6637 - accuracy: 0.5790 - val_loss: 0.4573 - val_accuracy: 0.7671\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 12s 99ms/step - loss: 0.4405 - accuracy: 0.7928 - val_loss: 0.3207 - val_accuracy: 0.8629\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 13s 101ms/step - loss: 0.3377 - accuracy: 0.8480 - val_loss: 0.1951 - val_accuracy: 0.9234\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.2254 - accuracy: 0.9050 - val_loss: 0.1226 - val_accuracy: 0.9637\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.1183 - accuracy: 0.9568 - val_loss: 0.0362 - val_accuracy: 0.9899\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.0618 - accuracy: 0.9790 - val_loss: 0.0586 - val_accuracy: 0.9829\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.0437 - accuracy: 0.9880 - val_loss: 0.0075 - val_accuracy: 0.9980\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.0228 - accuracy: 0.9950 - val_loss: 0.0068 - val_accuracy: 0.9990\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.0016 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReS4epgpUcj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a88fa11-82eb-4a37-bef5-b76ae8a77605"
      },
      "source": [
        "# Export model\n",
        "main_save_path = './my_models'\n",
        "saved_model_name = 'cs_410_text_classification_competition'\n",
        "saved_model_path = os.path.join(main_save_path, saved_model_name)\n",
        "\n",
        "preprocess_inputs = bert_preprocess_model.inputs\n",
        "bert_encoder_inputs = bert_preprocess_model(preprocess_inputs)\n",
        "bert_outputs = classifier_model(bert_encoder_inputs)\n",
        "model_for_export = tf.keras.Model(preprocess_inputs, bert_outputs)\n",
        "\n",
        "print(f'Saving {saved_model_path}')\n",
        "\n",
        "# Save everything on the Colab host (even the variables from TPU memory)\n",
        "save_options = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
        "model_for_export.save(saved_model_path, include_optimizer=False, options=save_options)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving ./my_models/cs_410_text_classification_competition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQR0lyEw37tS"
      },
      "source": [
        "# Reload model\n",
        "load_options = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
        "reloaded_model = tf.saved_model.load(saved_model_path, options=load_options)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpx-RznR4LZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5ad928-0627-4f13-e7bc-20306c6d7bde"
      },
      "source": [
        "# Download and preprocess test dataset\n",
        "test_url = 'https://raw.githubusercontent.com/CS410Fall2020/ClassificationCompetition/main/data/test.jsonl'\n",
        "test_path = tf.keras.utils.get_file('test.jsonl', test_url)\n",
        "\n",
        "test_dataset = preprocess_dataset(test_path, 'test')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/CS410Fall2020/ClassificationCompetition/main/data/test.jsonl\n",
            "1310720/1306842 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opumj84_CR1R"
      },
      "source": [
        "# Utility methods for testing\n",
        "def prepare(record):\n",
        "  \"\"\"Prepares records from processed dataset for prediction.\n",
        "    \n",
        "  Args:\n",
        "    record: dict of str Tensors.\n",
        "    \n",
        "  Returns:\n",
        "    A list of lists of str Tensors.\n",
        "  \"\"\"\n",
        "  model_inputs = [[record[ft]] for ft in ['context', 'response']]\n",
        "  return model_inputs\n",
        "\n",
        "def get_result(test_row, model):\n",
        "  \"\"\"Predicts whether a Twitter sarcasm test example is sarcasm or not sarcasm.\n",
        "    \n",
        "  Args:\n",
        "    test_row: list of str Tensors.\n",
        "    model: TensorFlow SavedModel for the sarcasm classifier.\n",
        "    \n",
        "  Returns:\n",
        "    A str, either 'SARCASM' or 'NOT_SARCASM', corresponding to the predicted result.\n",
        "  \"\"\"\n",
        "  \n",
        "  raw_result = model(list(test_row))\n",
        "  if tf.argmax(raw_result, axis=1)[0] == 1:\n",
        "    result_class = 'SARCASM'\n",
        "  else:\n",
        "    result_class = 'NOT_SARCASM'\n",
        "  return result_class\n",
        "\n",
        "def print_result(test_row, model):\n",
        "  \"\"\"Prints out the context, response, and predicted label for a Twitter sarcasm test example.\n",
        "    \n",
        "  Args:\n",
        "    test_row: list of str Tensors.\n",
        "    model: TensorFlow SavedModel for the sarcasm classifier.\n",
        "    \n",
        "  Returns:\n",
        "    None.\n",
        "  \"\"\"\n",
        "  \n",
        "  label = get_result(test_row, model)\n",
        "  print(f'context: {test_row[0]}')\n",
        "  print(f'response: {test_row[1]}')\n",
        "  print(f'prediction: {label}')\n",
        "  print()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMsDCbeMEix1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed58e5e7-3df6-47c0-b09b-755a5156063b"
      },
      "source": [
        "# Print some sample test set results\n",
        "test_size = tf.data.experimental.cardinality(test_dataset).numpy()\n",
        "\n",
        "for test_row in test_dataset.shuffle(test_size).map(prepare).take(5):\n",
        "  print_result(test_row, reloaded_model)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "context: [b'@USER @USER @USER It \\xe2\\x80\\x99 s obvious I \\xe2\\x80\\x99 m dealing with a double digit IQ . Have a good life .']\n",
            "response: [b'@USER @USER @USER Hahahahahah What a chump . No testicular fortitude at all . It \\xe2\\x80\\x99 s unsurprising that liberals lose with people like this . <URL>']\n",
            "prediction: SARCASM\n",
            "\n",
            "context: [b'@USER @USER asked me to respond to @USER . See attached . Thanks for the opportunity . #KXL <URL>']\n",
            "response: [b'@USER @USER @USER Imagine that . A politician making baseless accusations . Because has * never * done that before .']\n",
            "prediction: SARCASM\n",
            "\n",
            "context: [b'@USER @USER By all means you should initiate another failed impeachment , causing further embarrassment ( if that were even possible ) to your party , then go tear up some official documents like a toddler .']\n",
            "response: [b'@USER @USER @USER Yet you have no shame in supporting the biggest criminal in White House history .']\n",
            "prediction: SARCASM\n",
            "\n",
            "context: [b'@USER @USER Aaaayyyyyeeee I \\xe2\\x80\\x99 m the Hypemobile humie . I gatchu ! ! ! \\xf0\\x9f\\x98\\x9c \\xf0\\x9f\\x91\\x8c \\xf0\\x9f\\x8f\\xbc']\n",
            "response: [b'@USER @USER Oh ... OHHHH ! That \\xe2\\x80\\x99 s how it \\xe2\\x80\\x99 s gonna be ? My two bestfriends just gon \\xe2\\x80\\x99 team up on me ? \\xf0\\x9f\\x98\\xa1']\n",
            "prediction: NOT_SARCASM\n",
            "\n",
            "context: [b\"@USER @USER @USER Thank You so much , Diablo , My Dearest Friend ! I am grateful every day , as I am happy every day . I make those choices every day for me ! It doesn't matter what is going on , my choices stick . I give the gift of positivity to myself , to everyone I touch ! LOVE U XOXO <URL>\"]\n",
            "response: [b'@USER @USER @USER All good things are possible when the #heart illuminates the mind #ThinkBIGSundayWithMarsha #InspireThemRetweetTuesday <URL>']\n",
            "prediction: NOT_SARCASM\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjmEbXYB67rs"
      },
      "source": [
        "# Run model on test dataset and save results to file\n",
        "with open('./answer.txt', 'w') as file:\n",
        "  for i, test_row in enumerate(test_dataset.map(prepare)):\n",
        "    label = get_result(test_row, reloaded_model)\n",
        "    file.write('twitter_' + str(i + 1) + ',' + label + os.linesep)"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}